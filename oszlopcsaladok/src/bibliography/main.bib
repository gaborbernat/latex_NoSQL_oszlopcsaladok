@article{Codd1970,
  added-at = {2011-01-11T13:35:01.000+0100},
  author = {Codd, Edgar F.},
  biburl = {http://www.bibsonomy.org/bibtex/22ab1d4e5e14706178d39146504f420c2/enitsirhc},
  interhash = {c64b7366f663306a0cf59641ee0b80c8},
  intrahash = {2ab1d4e5e14706178d39146504f420c2},
  journal = {CACM},
  keywords = {relationaledatenbank relationaldatabase},
  month = {June},
  number = 6,
  pages = {377--387},
  read = {ja},
  timestamp = {2011-01-11T13:35:01.000+0100},
  title = {{A Relational Model of Data for Large Shared Data Banks}},
  volume = 13,
  year = 1970
}

@book{EdlichFriedlandHampeBrauer201010,
  added-at = {2011-01-13T10:02:03.000+0100},
  author = {Edlich, Stefan and Friedland, Achim and Hampe, Jens and Brauer, Benjamin},
  biburl = {http://www.bibsonomy.org/bibtex/2b295fbbefaa11adbc2f10e247cba25ab/stroeh},
  interhash = {918f916344d4c39d3831a967a283b0c4},
  intrahash = {b295fbbefaa11adbc2f10e247cba25ab},
  isbn = {9783446423558},
  keywords = {nosql web-2.0-datenbanken},
  month = {10},
  price = {EUR 29,90},
  publisher = {Hanser Fachbuchverlag},
  timestamp = {2011-01-13T10:02:03.000+0100},
  title = {NoSQL: Einstieg in die Welt nichtrelationaler Web 2.0 Datenbanken},
  totalpages = {304},
  url = {http://amazon.de/o/ASIN/3446423559/},
  year = 2010
}

@webpage{Edlich2011,
  added-at = {2011-08-19T12:45:25.000+0200},
  author = {Edlich, Stefan},
  biburl = {http://www.bibsonomy.org/bibtex/20873f5bbe32ec5e9f3ffaf1cbd248322/zazi},
  interhash = {a872db6d7dfdd43372fcb8cc3a0c7f85},
  intrahash = {0873f5bbe32ec5e9f3ffaf1cbd248322},
  keywords = {imported},
  lastchecked = {12-01-2011},
  month = {January},
  owner = {zazi},
  timestamp = {2011-08-19T12:45:25.000+0200},
  title = {{NOSQL Databases}},
  url = {http://nosql-database.org/},
  year = 2011
}

@inproceedings{Chang2006,
  abstract = {Bigtable is a distributed storage system for managing structured data that is designed to scale to a very large size: petabytes of data across thousands of commodity servers. Many projects at Google store data in Bigtable, including web indexing, Google Earth, and Google Finance. These applications place very different demands on Bigtable, both in terms of data size (from URLs to web pages to satellite imagery) and latency requirements (from backend bulk processing to real-time data serving). Despite these varied demands, Bigtable has successfully provided a flexible, high-performance solution for all of these Google products. In this paper we describe the simple data model provided by Bigtable, which gives clients dynamic control over data layout and format, and we describe the design and implementation of Bigtable.},
  added-at = {2011-07-11T10:41:49.000+0200},
  author = {Chang, Fay and Dean, Jeffrey and Ghemawat, Sanjay and Hsieh, Wilson C. and Wallach, Deborah A. and Burrows, Mike and Chandra, Tushar and Fikes, Andrew and Gruber, Robert E.},
  biburl = {http://www.bibsonomy.org/bibtex/208eed5d4b530bf1f94eb6d0ea1570a8c/stroeh},
  booktitle = {Proceedings of the 7th USENIX Symposium on Operating Systems Design and Implementation (OSDI'06)},
  interhash = {badf4db5d31f7ee7318ca619a589f2e1},
  intrahash = {08eed5d4b530bf1f94eb6d0ea1570a8c},
  keywords = {bigtable hadoop hbase},
  timestamp = {2011-07-11T10:41:49.000+0200},
  title = {Bigtable: A distributed storage system for structured data},
  url = {http://labs.google.com/papers/bigtable.html},
  year = 2006
}

@article{dean2008mapreduce,
  abstract = {MapReduce is a programming model and an associated implementation for processing and generating large datasets that is amenable to a broad variety of real-world tasks. Users specify the computation in terms of a <i>map</i> and a <i>reduce</i> function, and the underlying runtime system automatically parallelizes the computation across large-scale clusters of machines, handles machine failures, and schedules inter-machine communication to make efficient use of the network and disks. Programmers find the system easy to use: more than ten thousand distinct MapReduce programs have been implemented internally at Google over the past four years, and an average of one hundred thousand MapReduce jobs are executed on Google's clusters every day, processing a total of more than twenty petabytes of data per day.},
  acmid = {1327492},
  added-at = {2012-06-19T17:23:37.000+0200},
  address = {New York, NY, USA},
  author = {Dean, Jeffrey and Ghemawat, Sanjay},
  biburl = {http://www.bibsonomy.org/bibtex/2bff539224836d703c2d21141985fa1a3/jaeschke},
  doi = {10.1145/1327452.1327492},
  interhash = {b8a00982bf087c8543855897b7362a04},
  intrahash = {bff539224836d703c2d21141985fa1a3},
  issn = {0001-0782},
  issue_date = {January 2008},
  journal = {Communications of the ACM},
  keywords = {cloud computing data database mapreduce parallel processing},
  month = jan,
  number = 1,
  numpages = {7},
  pages = {107--113},
  publisher = {ACM},
  timestamp = {2012-06-19T17:23:37.000+0200},
  title = {MapReduce: simplified data processing on large clusters},
  url = {http://doi.acm.org/10.1145/1327452.1327492},
  volume = 51,
  year = 2008
}

@article{googlefilesystem,
  added-at = {2010-04-06T16:35:05.000+0200},
  address = {New York, NY, USA},
  author = {Ghemawat, Sanjay and Gobioff, Howard and Leung, Shun-Tak},
  biburl = {http://www.bibsonomy.org/bibtex/20f2c47d19628406c228a26ce6155fa11/chesteve},
  doi = {http://doi.acm.org/10.1145/1165389.945450},
  interhash = {e2569aaef718682ab6729d671a3eac65},
  intrahash = {0f2c47d19628406c228a26ce6155fa11},
  issn = {0163-5980},
  journal = {SIGOPS Oper. Syst. Rev.},
  keywords = {imported},
  number = 5,
  pages = {29--43},
  publisher = {ACM},
  timestamp = {2010-04-06T16:35:05.000+0200},
  title = {{The Google File System}},
  volume = 37,
  year = 2003
}


@article{amazonDynamo,
  added-at = {2010-02-02T22:52:07.000+0100},
  address = {New York, NY, USA},
  author = {DeCandia, Giuseppe and Hastorun, Deniz and Jampani, Madan and Kakulapati, Gunavardhan and Lakshman, Avinash and Pilchin, Alex and Sivasubramanian, Swaminathan and Vosshall, Peter and Vogels, Werner},
  biburl = {http://www.bibsonomy.org/bibtex/2b57300b494b1b163d0fca4b6dc8f2676/chesteve},
  doi = {http://doi.acm.org/10.1145/1323293.1294281},
  interhash = {5a38a3a7830286733636ae732d0b01cb},
  intrahash = {b57300b494b1b163d0fca4b6dc8f2676},
  issn = {0163-5980},
  journal = {SIGOPS Oper. Syst. Rev.},
  keywords = {imported},
  number = 6,
  pages = {205--220},
  publisher = {ACM},
  timestamp = {2010-02-02T22:52:07.000+0100},
  title = {Dynamo: amazon's highly available key-value store},
  volume = 41,
  year = 2007
}

@article{ColumnOriantedAbadiBH09,
  added-at = {2012-08-08T10:23:15.000+0200},
  author = {Abadi, Daniel J. and Boncz, Peter A. and Harizopoulos, Stavros},
  biburl = {http://www.bibsonomy.org/bibtex/2bf1a7f12a78676fa434c0e287ca9a332/rainerunfug},
  description = {dblp},
  ee = {http://www.vldb.org/pvldb/2/vldb09-tutorial6.pdf},
  interhash = {a4f7af62e3a6df6ab92e6005ed061f89},
  intrahash = {bf1a7f12a78676fa434c0e287ca9a332},
  journal = {PVLDB},
  keywords = {column database},
  number = 2,
  pages = {1664-1665},
  timestamp = {2012-08-08T10:23:15.000+0200},
  title = {Column oriented Database Systems.},
  url = {http://dblp.uni-trier.de/db/journals/pvldb/pvldb2.html#AbadiBH09},
  volume = 2,
  year = 2009
}

@Unpublished{WideColumnStore,
  author = 	 {Prof. Dr. Marc H. Scholl, Dr. Christian Gr체n.},
  title = 	 {Lecture: Advanced Database Technologies},
  note = 	 {DBIS Group - Universit채t Konstanz},
  OPTmonth = 	 {June},
  OPTyear = 	 {2011},
  OPTannote = 	 {DBIS Group - Universit채t Konstanz}
}

@book{hbase2011george,
  added-at = {2011-09-29T09:34:52.000+0200},
  asin = {1449396100},
  author = {George, Lars},
  biburl = {http://www.bibsonomy.org/bibtex/2b062d157acb61f49cacc068895e80819/stroeh},
  description = {HBase: The Definitive Guide: Amazon.de: Lars George: Englische B체cher},
  dewey = {005},
  ean = {9781449396107},
  edition = 1,
  interhash = {7555458c85c1d4e7573d1d7f5db7f703},
  intrahash = {b062d157acb61f49cacc068895e80819},
  isbn = {1449396100},
  keywords = {definitive guide hbase},
  publisher = {O'Reilly Media},
  timestamp = {2011-09-29T09:34:52.000+0200},
  title = {HBase: The Definitive Guide},
  url = {http://www.amazon.de/HBase-Definitive-Guide-Lars-George/dp/1449396100/ref=sr_1_1?ie=UTF8&qid=1317281653&sr=8-1},
  year = 2011
}

@book{books/daglib/0029284,
  added-at = {2012-09-04T00:00:00.000+0200},
  author = {White, Tom},
  biburl = {http://www.bibsonomy.org/bibtex/2b722dca658ebac9693e10a7a26ef1af2/dblp},
  ee = {http://www.oreilly.de/catalog/9781449311520/index.html},
  interhash = {5d83aebd7b8dca23f716149524aef868},
  intrahash = {b722dca658ebac9693e10a7a26ef1af2},
  isbn = {978-1-449-31152-0},
  keywords = {dblp},
  pages = {I-XXIII, 1-657},
  publisher = {O'Reilly},
  timestamp = {2012-09-04T00:00:00.000+0200},
  title = {Hadoop - The Definitive Guide: Storage and Analysis at Internet Scale (3. ed., revised and updated).},
  year = 2012
}

@Manual{CassandraManual,
  title = 	 {Apache Cassandra 1.1 Documentation},
  OPTorganization = {DataStax},
  OPTedition = 	 {1.1},
  OPTmonth = 	 {october},
  OPTyear = 	 {2012},
}

@article{Lakshman:2010:CDS:1773912.1773922,
  abstract = {Cassandra is a distributed storage system for managing very large amounts of structured data spread out across many commodity servers, while providing highly available service with no single point of failure. Cassandra aims to run on top of an infrastructure of hundreds of nodes (possibly spread across different data centers). At this scale, small and large components fail continuously. The way Cassandra manages the persistent state in the face of these failures drives the reliability and scalability of the software systems relying on this service. While in many ways Cassandra resembles a database and shares many design and implementation strategies therewith, Cassandra does not support a full relational data model; instead, it provides clients with a simple data model that supports dynamic control over data layout and format. Cassandra system was designed to run on cheap commodity hardware and handle high write throughput while not sacrificing read efficiency.},
  acmid = {1773922},
  added-at = {2012-04-25T10:41:56.000+0200},
  address = {New York, NY, USA},
  author = {Lakshman, Avinash and Malik, Prashant},
  biburl = {http://www.bibsonomy.org/bibtex/2e25c396b9ea318f4c0591e759507a7ed/jmlordo},
  description = {Cassandra},
  doi = {10.1145/1773912.1773922},
  interhash = {8d90a233678aa931aee0bccb68c7bf04},
  intrahash = {e25c396b9ea318f4c0591e759507a7ed},
  issn = {0163-5980},
  issue_date = {April 2010},
  journal = {SIGOPS Oper. Syst. Rev.},
  keywords = {2012 cassandra nosql seminar summer talk},
  month = apr,
  number = 2,
  numpages = {6},
  pages = {35--40},
  publisher = {ACM},
  timestamp = {2012-04-25T10:41:56.000+0200},
  title = {Cassandra: a decentralized structured storage system},
  url = {http://doi.acm.org/10.1145/1773912.1773922},
  volume = 44,
  year = 2010
}

@inproceedings{GilbertLynch2002,
  added-at = {2011-11-13T21:29:53.000+0100},
  author = {Gilbert, Seth and Lynch, Nancy},
  biburl = {http://www.bibsonomy.org/bibtex/2f6a0a6a6cfb4d2834b233636184fa317/nosebrain},
  booktitle = {In ACM SIGACT News},
  interhash = {db3ba0435f92c8b28fdd740ec64cbb34},
  intrahash = {f6a0a6a6cfb4d2834b233636184fa317},
  keywords = {cap nosql sys:hidden:my:bachelor sys:read},
  pages = 2002,
  timestamp = {2011-11-13T21:29:53.000+0100},
  title = {Brewer's Conjecture and the Feasibility of Consistent Available Partition-Tolerant Web Services},
  url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.20.1495&rep=rep1&type=pdf},
  year = 2002
}

@inproceedings{Brewer2000,
  added-at = {2011-07-03T17:44:37.000+0200},
  author = {Brewer, Eric A.},
  biburl = {http://www.bibsonomy.org/bibtex/2ac8e9a3cd153905bcdeb862e23272975/stroeh},
  booktitle = {Symposium on Principles of Distributed Computing (PODC)},
  interhash = {ed89cb5eca903d45cd2fa4bcde961eb5},
  intrahash = {ac8e9a3cd153905bcdeb862e23272975},
  keywords = {cap nosql},
  timestamp = {2011-07-03T17:44:37.000+0200},
  title = {Towards Robust Distributed Systems.},
  url = {http://www.cs.berkeley.edu/~brewer/cs262b-2004/PODC-keynote.pdf},
  year = 2000
}

@webpage{JulianBrowneCAP,
  added-at = {2012-10-13T12:45:25.000+0200},
  author = {Browne, Julian},
  keywords = {blog entry},
  lastchecked = {13-10-2012},
  month = {January},
  owner = {Julian},
  timestamp = {2012-10-13T12:45:25.000+0200},
  title = {{Brewer's CAP Theorem}},
  url = {http://www.julianbrowne.com/article/viewer/brewers-cap-theorem},
  year = 2009
}

@inproceedings{chubby2006burrows,
  added-at = {2012-02-05T14:16:17.000+0100},
  author = {Burrows, Michael},
  biburl = {http://www.bibsonomy.org/bibtex/2b591fb23923b92b996c17d6034c42da0/nosebrain},
  booktitle = {OSDI},
  ee = {http://www.usenix.org/events/osdi06/tech/burrows.html},
  interhash = {80d0a9e7ae04558c4cfc8ed8883710c7},
  intrahash = {b591fb23923b92b996c17d6034c42da0},
  keywords = {chubby distributed lock service sys:hidden:my:bachelor system},
  pages = {335-350},
  publisher = {USENIX Association},
  timestamp = {2012-02-05T14:16:17.000+0100},
  title = {The Chubby Lock Service for Loosely-Coupled Distributed Systems.},
  year = 2006
}





	
